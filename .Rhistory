typeof(var)
is.vector(var)
vec1 <- c(1,2,3,4,5)
vec1
vec2 <- 1:5
vec2
vec2 <- c(TRUE, FALSE, TRUE)
vec3 <- c("Ram","Shyam","Hari")
vec4 <- c(12+41, 4+131)
vec5 <- c("Ram",TRUE, 22, 4+31, 12.34)
typeof(vec5)
vec5
is.vector(vec5)
as.character(vec1)
str_vec1 <- as.character(vec1)
str_vec1
emp_vec <- vector(mode="character",length = 3)
emp_vec
emp_vec[1]="R"
emp_vec[2]="A"
emp_vec[3]="N"
emp_vec
#matrix
mat <- matrix(nrow=3,ncol=3)
mat
mat2 <-matrix(c("ram", "aaksh", "bigesh", "sanjip"),nrow=2,ncol=2)
mat2
#cbind, rbind
x=1:6
y=6:12
x
y
col_mat <-cbind(x,y)
row_mat<-rbind(x,y)
col_mat
row_mat
#factor
fac <- factor(c("Male","Female","Female","Male","Female","Male"),levels=c("Male","Female"),labels = c(1,2))
fac
table(fac)
table(fac2)
head(df)
df =read.csv("Social_Network_Ads.csv")
df =read.csv("Social_Network_Ads.csv")
df =read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
df = read.csv("Social_Network_Ads.csv")
# Set working directory
setwd("/Users/sandipmahata/Desktop/data mining/Sales Dataset")
# Importing all datasets into a list
datasets <- list(
January = read.csv("Sales_January_2019.csv"),
February = read.csv("Sales_February_2019.csv"),
March = read.csv("Sales_March_2019.csv"),
April = read.csv("Sales_April_2019.csv"),
May = read.csv("Sales_May_2019.csv"),
June = read.csv("Sales_June_2019.csv"),
July = read.csv("Sales_July_2019.csv"),
August = read.csv("Sales_August_2019.csv"),
September = read.csv("Sales_September_2019.csv"),
October = read.csv("Sales_October_2019.csv"),
November = read.csv("Sales_November_2019.csv"),
December = read.csv("Sales_December_2019.csv")
)
# Inspect the first dataset
head(datasets[[1]])
# Print summary of a sample dataset
summary(datasets[[1]])
# Loading required libraries for data manipulation and visualization
library(dplyr)
library(ggplot2)
library(tidyr)  # Added for `separate` function
# Function to remove rows with non-numeric Order IDs and ensure correct numeric types
clean_dataset <- function(data) {
data %>%
filter(grepl("^[0-9]+$", Order.ID)) %>%  # Keep rows where Order.ID is numeric
mutate(
Order.ID = as.numeric(Order.ID),
Quantity.Ordered = as.numeric(Quantity.Ordered),
Price.Each = as.numeric(Price.Each)
)
}
# Apply the cleaning function to all datasets
datasets_cleaned <- lapply(datasets, clean_dataset)
# Print summary of the cleaned January dataset
summary(datasets_cleaned[[1]])
# Combine all cleaned datasets into one dataset for the entire year
datasets_combined <- do.call(rbind, datasets_cleaned)
# List of month names corresponding to each dataset
month_names <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")
# Add a Month column to each dataset before combining
for (i in seq_along(datasets_cleaned)) {
datasets_cleaned[[i]]$Month <- month_names[i]
}
# Now combine all datasets with the Month column
datasets_combined <- do.call(rbind, datasets_cleaned)
# Create a summary data frame for total sales and average quantity ordered across all months
summary_df <- data.frame(
Month = month_names,
Average_Quantity = sapply(datasets_cleaned, function(data) mean(data$Quantity.Ordered, na.rm = TRUE))
)
# View the summary data frame
print(summary_df)
# Data Preprocessing
# Convert "Order Date" to Date format and extract components (Month, Day, Hour) for all datasets
for (i in 1:length(datasets_cleaned)) {
datasets[[i]]$Order.Date <- as.POSIXct(datasets[[i]]$Order.Date, format = "%m/%d/%y %H:%M")
datasets[[i]]$Month <- format(datasets[[i]]$Order.Date, "%m")
datasets[[i]]$Day <- format(datasets[[i]]$Order.Date, "%d")
datasets[[i]]$Hour <- format(datasets[[i]]$Order.Date, "%H")
}
# Inspect the changes in the first dataset
head(datasets[[1]])
library(stringr)
# Updated function to process sales data
process_sales_data <- function(data) {
# Create Total Sales column
data$Total.Sales <- data$Quantity.Ordered * data$Price.Each
# Check if 'Purchase.Address' exists and is properly formatted
data <- data %>%
mutate(
Purchase.Address = as.character(Purchase.Address)  # Ensure it's a character type
) %>%
separate(Purchase.Address, into = c("Street", "City", "State.Zip"), sep = ",", extra = "merge", fill = "right") %>%
separate(State.Zip, into = c("State", "Zip.Code"), sep = " ", extra = "merge", fill = "right")
return(data)
}
# Re-apply the function to all datasets
datasets_processed <- lapply(datasets_cleaned, process_sales_data)
# Verify the changes in the first dataset
head(datasets_processed[[1]])
# Data Visualization
# Add a Month column to each dataset and calculate Total Sales for each record
for (i in seq_along(datasets_cleaned)) {
datasets_cleaned[[i]]$Total.Sales <- datasets_cleaned[[i]]$Price.Each * datasets_cleaned[[i]]$Quantity.Ordered
datasets_cleaned[[i]]$Month <- month_names[i]  # Assign corresponding month name
}
# Combine all datasets with the Total Sales and Month columns
datasets_combined <- do.call(rbind, datasets_cleaned)
# Ensure the Month column is treated as a factor for correct plotting
datasets_combined$Month <- factor(datasets_combined$Month, levels = month_names)
# Summarize total sales by month
monthly_sales <- datasets_combined %>%
group_by(Month) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
#Create a bar plot for total sales across all months
ggplot(monthly_sales, aes(x = Month, y = Total_Sales)) +
geom_bar(stat = "identity", fill = "red", color = "darkblue") +
labs(
title = "Total Sales for Each Month (2019)",
x = "Month",
y = "Total Sales"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#data visualization
# Set working directory
setwd("/Users/sandipmahata/Desktop/data mining/Sales Dataset")
# Importing all datasets into a list
datasets <- list(
January = read.csv("Sales_January_2019.csv"),
February = read.csv("Sales_February_2019.csv"),
March = read.csv("Sales_March_2019.csv"),
April = read.csv("Sales_April_2019.csv"),
May = read.csv("Sales_May_2019.csv"),
June = read.csv("Sales_June_2019.csv"),
July = read.csv("Sales_July_2019.csv"),
August = read.csv("Sales_August_2019.csv"),
September = read.csv("Sales_September_2019.csv"),
October = read.csv("Sales_October_2019.csv"),
November = read.csv("Sales_November_2019.csv"),
December = read.csv("Sales_December_2019.csv")
)
summary(datasets[[1]])#order id and price data type is character so  data is noisy
#Data Exploration
#Data cleaning and removing misding value and null value and combining all data in a unit
library(dplyr)
# Add a 'Month' column to each dataset before combining them
datasets_cleaned <- lapply(names(datasets), function(month) {
data <- datasets[[month]]
data$Month <- month  # Add a 'Month' column with the respective month name
return(data)
})
# Combine all datasets into one data frame
df <- do.call(rbind, datasets_cleaned)
# Check if 'Quantity.Ordered' and 'Price.Each' columns exist
if ("Quantity.Ordered" %in% colnames(df) & "Price.Each" %in% colnames(df)) {
# Ensure 'Quantity.Ordered' and 'Price.Each' are numeric
df$Quantity.Ordered <- as.numeric(df$Quantity.Ordered)
df$Price.Each <- as.numeric(df$Price.Each)
# Create the Total.Sales column
df$Total.Sales <- df$Quantity.Ordered * df$Price.Each
} else {
stop("Columns 'Quantity.Ordered' or 'Price.Each' not found in the dataset")
}
# Remove rows with missing or NA values in any column
df <- df %>%
filter(complete.cases(.))  # Removes rows with NA
# Optionally, drop empty strings as well
df<- df %>%
filter_all(all_vars(. != ""))
# Inspect the cleaned data
head(df)
#Basic summary
# Basic summary of the dataset
summary(df)
# Number of records in the combined dataset
num_records <- nrow(df)
# Range of key values in 'Total.Sales', 'Quantity.Ordered', and 'Price.Each'
range_values <- data.frame(
Total_Sales_Range = range(df$Total.Sales, na.rm = TRUE),
Quantity_Ordered_Range = range(df$Quantity.Ordered, na.rm = TRUE),
Price_Each_Range = range(df$Price.Each, na.rm = TRUE)
)
# Basic statistics: Total sales and average quantity ordered
total_sales <- sum(df$Total.Sales, na.rm = TRUE)
avg_quantity <- mean(df$Quantity.Ordered, na.rm = TRUE)
# Display results
cat("Number of records:", num_records, "\n")
cat("Total Sales:", total_sales, "\n")
cat("Average Quantity Ordered:", avg_quantity, "\n")
print(range_values)
# Calculate sales and average for each month
monthly_summary <- df %>%
group_by(Month) %>%
summarise(
Total_Sales = sum(Total.Sales, na.rm = TRUE),
Average_Quantity = mean(Quantity.Ordered, na.rm = TRUE)
)
# Sorting the monthly summary by Total Sales
monthly_summary_sorted <- monthly_summary %>%
arrange(Total_Sales)
# Display the sorted summary
print(monthly_summary_sorted)
#Date and Time Analysis:
#correcting the date format in a proper manner
df$Order.Date <- as.POSIXct(df$Order.Date, format = "%m/%d/%y %H:%M")
df$Month <- format(df$Order.Date, "%m")
df$Day <- format(df$Order.Date, "%d")
df$Hour <- format(df$Order.Date, "%H")
#Data Preprocessing:
#insuring the appropriate format for analysis of coloumns
summary(df)
#converting day hour and month in numerical variable
df$Month = as.numeric(df$Month)
df$Day = as.numeric(df$Day)
df$Hour = as.numeric(df$Hour)
# Drop the 'Order.Date' column
df <- df %>%
select(-Order.Date)
# Check the result to ensure 'Order.Date' is removed
head(df)
#Feature Engineering
# Feature Engineering: Split 'Purchase.Address' into 'Street', 'City', 'State', and 'Zip.Code'
library(tidyr)
# Ensure Purchase.Address is character type and then extract the components using regular expressions
df <- df %>%
mutate(
Purchase.Address = as.character(Purchase.Address)  # Ensure it's a character type
) %>%
# Use regular expression to extract Street, City, State, and Zip.Code directly
extract(
Purchase.Address,
into = c("Street", "City", "State", "Zip.Code"),
regex = "^(.+),\\s*(.+),\\s*([A-Z]{2})\\s*(\\d{5})$"
) %>%
# Trim whitespace for all fields just in case
mutate(
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Create a new 'Week' column based on the 'Day' column
df <- df %>%
mutate(
Week = case_when(
Day >= 0 & Day <= 7 ~ 1,
Day >= 8 & Day <= 14 ~ 2,
Day >= 15 & Day <= 21 ~ 3,
Day >= 22 & Day <= 28 ~ 4,
Day >= 29 & Day <= 35 ~ 5,
TRUE ~ NA_real_  # In case there's an invalid day value
)
)
# Inspect the new 'Week' column
head(df[, c("Day", "Week")], 10)
# Count duplicate Order.ID values
duplicate_count <- df %>%
group_by(Order.ID) %>%
summarise(Order_Count = n()) %>%
filter(Order_Count > 1) %>%
nrow()
# Display the count of duplicate Order.IDs
cat("Number of duplicate Order.IDs:", duplicate_count, "\n")
#assuming order id is as per the same customer and making new dataframe
# Clean and trim whitespace from relevant columns
df <- df %>%
mutate(
Order.ID = trimws(Order.ID),  # Trim whitespace
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Create a new data frame with unique Order.IDs, their repetition count, and total sales
order_id_df <- df %>%
group_by(Order.ID, Street, City, State, Zip.Code) %>%
summarise(
Repeat_Count = n(),  # Count how many times each Order.ID appears
Total_Sales = sum(Total.Sales, na.rm = TRUE),  # Sum of Total Sales for each Order.ID
.groups = 'drop'  # Avoid warning about grouping
) %>%
# Replace empty strings and NA values with "Not Available"
mutate(
Order.ID = ifelse(Order.ID == "", "Not Available", Order.ID),
Street = ifelse(Street == "", "Not Available", Street),
City = ifelse(is.na(City), "Not Available", City),
State = ifelse(State == "", "Not Available", State),
Zip.Code = ifelse(Zip.Code == "", "Not Available", Zip.Code)
) %>%
# Remove rows where Total_Sales is 0
filter(Total_Sales > 0)
# Display the new data frame
print(order_id_df)
# Create the 'time_frame' column based on the 'Hour' column
df <- df %>%
mutate(
time_frame = case_when(
Hour >= 0 & Hour < 8 ~ "Morning",
Hour >= 8 & Hour < 16 ~ "Evening",
Hour >= 16 & Hour < 24 ~ "Night",
TRUE ~ NA_character_  # In case there are any unexpected values
)
)
# Inspect the updated dataframe
head(df)
# Load the necessary libraries
library(leaflet)
library(tidygeocoder)
library(dplyr)
# Ensure that your dataframe 'df' has City and State columns
if (!all(c("City", "State") %in% colnames(df))) {
stop("Dataframe must contain 'City' and 'State' columns.")
}
# Count the number of customers in each city by state
city_counts <- df %>%
group_by(State, City) %>%
summarise(Frequency = n(), .groups = 'drop')  # This will give you the number of customers per city by state
# Create a new column combining City and State for geocoding
city_counts <- city_counts %>%
mutate(Location = paste(City, State, sep = ", "))  # Create a Location column
# Geocode the cities (using OpenStreetMap)
geocoded_cities <- city_counts %>%
geocode(Location, method = 'osm', full_results = TRUE)  # Get full results for more details
# Check if geocoding was successful and if 'long' and 'lat' are present
if (!all(c("long", "lat") %in% colnames(geocoded_cities))) {
stop("Geocoding failed: Missing 'long' or 'lat' columns.")
}
# Combine geocoded data with frequency data
geocoded_cities <- geocoded_cities %>%
select(long, lat, Location) %>%  # Select necessary columns
left_join(city_counts, by = c("Location" = "Location"))  # Join to bring in Frequency
# Ensure the combined data has the necessary columns
if (!"Frequency" %in% colnames(geocoded_cities)) {
stop("Frequency column not found after joining.")
}
head(geocoded_cities)
#Data visualization
library(ggplot2)
# Summarize total sales by state
state_sales_summary <- df %>%
group_by(State) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
# Create a bar plot to visualize total sales for each state
ggplot(state_sales_summary, aes(x = State, y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(
title = "Total Sales by State",
x = "State",
y = "Total Sales"
) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Count the total Order IDs by State
order_count_by_state <- df %>%
group_by(State) %>%
summarise(Total_Orders = n_distinct(Order.ID)) %>%  # Count unique Order IDs
arrange(desc(Total_Orders))  # Sort by Total Orders in descending order
# Display the summarized data (optional)
print(order_count_by_state)
# Create a bar plot for total Order IDs by State
ggplot(order_count_by_state, aes(x = reorder(State, -Total_Orders), y = Total_Orders)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Total Order Counts by State",
x = "State",
y = "Total Order Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better visibility
# Summarize Total Sales by Week
weekly_sales <- df %>%
group_by(Week) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
# Create a line graph for Total.Sales by Week
ggplot(weekly_sales, aes(x = Week, y = Total_Sales)) +
geom_line(color = "blue", size = 1) +  # Line graph
geom_point(color = "red", size = 2) +  # Points for each week
labs(title = "Total Sales by Week",
x = "Week",
y = "Total Sales") +
theme_minimal()
# Summarize the total sales by time_frame and Month
sales_summary <- df %>%
group_by(Month, time_frame) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE), .groups = 'drop')
# Create the grouped bar plot
ggplot(sales_summary, aes(x = Month, y = Total_Sales, fill = time_frame)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Total Sales by Time Frame and Month",
x = "Month",
y = "Total Sales") +
scale_fill_manual(values = c("Morning" = "lightblue", "Evening" = "orange", "Night" = "darkblue")) +
theme_minimal()
# Summarize total sales by time_frame
time_frame_summary <- df %>%
group_by(time_frame) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE), .groups = 'drop')
# Calculate the percentage of total sales for each time_frame
time_frame_summary <- time_frame_summary %>%
mutate(Percentage = Total_Sales / sum(Total_Sales) * 100)
# Create pie chart with percentage labels
ggplot(time_frame_summary, aes(x = "", y = Total_Sales, fill = time_frame)) +
geom_bar(stat = "identity", width = 1) +
coord_polar("y", start = 0) +  # Convert to pie chart
labs(title = "Total Sales Distribution by Time Frame") +
scale_fill_manual(values = c("Morning" = "red", "Evening" = "orange", "Night" = "green")) +
theme_void() +  # Remove axis labels and gridlines for pie chart aesthetics
geom_text(aes(label = paste0(round(Percentage, 1), "%")),  # Add percentage labels
position = position_stack(vjust = 0.5))  # Position labels in the center of the slices
#Sales Trend Over Time
library(ggplot2)
# Plot total sales by month
ggplot(monthly_summary_sorted, aes(x = Month, y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Total Sales by Month", x = "Month", y = "Total Sales") +
theme_minimal()
# Summarise sales by product
all_products <- df %>%
group_by(Product) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE)) %>%
arrange(desc(Total_Sales))  # No head() function
# Plot all products
ggplot(all_products, aes(x = reorder(Product, -Total_Sales), y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Total Sales by Product", x = "Product", y = "Total Sales") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#Create a bar plot comparing total sales by city to see which cities have the highest sales
city_sales <- df %>%
group_by(City) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE)) %>%
arrange(desc(Total_Sales))
ggplot(city_sales, aes(x = reorder(City, -Total_Sales), y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Total Sales by City", x = "City", y = "Total Sales") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Sales by Time Frame and State
sales_by_time_state <- df %>%
group_by(State, time_frame) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE), .groups = 'drop')
ggplot(sales_by_time_state, aes(x = State, y = Total_Sales, fill = time_frame)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Sales by Time Frame and State", x = "State", y = "Total Sales") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
facet_wrap(~ time_frame)
#Customer Segmentation by Purchase
customer_segmentation <- df %>%
group_by(Order.ID) %>%
summarise(Total_Sales = sum(Total.Sales), Average_Order_Size = mean(Quantity.Ordered), .groups = 'drop')
ggplot(customer_segmentation, aes(x = Total_Sales, y = Average_Order_Size)) +
geom_point(alpha = 0.6) +
labs(title = "Customer Segmentation by Total Sales and Average Order Size", x = "Total Sales", y = "Average Order Size") +
theme_minimal()
# Plot the cities on a leaflet map
leaflet(geocoded_cities) %>%
addTiles() %>%  # Add base map tiles
addCircles(
lng = ~long, lat = ~lat,
popup = ~paste(City, State, "<br>Customers: ", Frequency),  # Show frequency in popup
radius = 10000,  # Adjust circle size as needed
weight = 1,
color = ~ifelse(Frequency == 1, "green", ifelse(Frequency == 2, "orange", "red")),  # Direct color assignment based on frequency
fillOpacity = 0.5
) %>%
addMarkers(
lng = ~long, lat = ~lat,
label = ~as.character(Frequency),  # Show customer count in label
labelOptions = labelOptions(noHide = TRUE, textOnly = FALSE, direction = "auto")
)
