# Create the Total.Sales column
df$Total.Sales <- df$Quantity.Ordered * df$Price.Each
} else {
stop("Columns 'Quantity.Ordered' or 'Price.Each' not found in the dataset")
}
# Remove rows with missing or NA values in any column
df <- df %>%
filter(complete.cases(.))  # Removes rows with NA
# Optionally, drop empty strings as well
df<- df %>%
filter_all(all_vars(. != ""))
# Inspect the cleaned data
head(df)
#Basic summary
# Basic summary of the dataset
summary(df)
# Number of records in the combined dataset
num_records <- nrow(df)
# Range of key values in 'Total.Sales', 'Quantity.Ordered', and 'Price.Each'
range_values <- data.frame(
Total_Sales_Range = range(df$Total.Sales, na.rm = TRUE),
Quantity_Ordered_Range = range(df$Quantity.Ordered, na.rm = TRUE),
Price_Each_Range = range(df$Price.Each, na.rm = TRUE)
)
# Basic statistics: Total sales and average quantity ordered
total_sales <- sum(df$Total.Sales, na.rm = TRUE)
avg_quantity <- mean(df$Quantity.Ordered, na.rm = TRUE)
# Display results
cat("Number of records:", num_records, "\n")
cat("Total Sales:", total_sales, "\n")
cat("Average Quantity Ordered:", avg_quantity, "\n")
print(range_values)
# Calculate sales and average for each month
monthly_summary <- df %>%
group_by(Month) %>%
summarise(
Total_Sales = sum(Total.Sales, na.rm = TRUE),
Average_Quantity = mean(Quantity.Ordered, na.rm = TRUE)
)
# Sorting the monthly summary by Total Sales
monthly_summary_sorted <- monthly_summary %>%
arrange(Total_Sales)
# Display the sorted summary
print(monthly_summary_sorted)
#Date and Time Analysis:
#correcting the date format in a proper manner
df$Order.Date <- as.POSIXct(df$Order.Date, format = "%m/%d/%y %H:%M")
df$Month <- format(df$Order.Date, "%m")
df$Day <- format(df$Order.Date, "%d")
df$Hour <- format(df$Order.Date, "%H")
#Data Preprocessing:
#insuring the appropriate format for analysis of coloumns
summary(df)
summary(df)
#insuring the appropriate format for analysis of coloumns
summary(df)
# Set working directory
setwd("/Users/sandipmahata/Desktop/data mining/Sales Dataset")
# Importing all datasets into a list
datasets <- list(
January = read.csv("Sales_January_2019.csv"),
February = read.csv("Sales_February_2019.csv"),
March = read.csv("Sales_March_2019.csv"),
April = read.csv("Sales_April_2019.csv"),
May = read.csv("Sales_May_2019.csv"),
June = read.csv("Sales_June_2019.csv"),
July = read.csv("Sales_July_2019.csv"),
August = read.csv("Sales_August_2019.csv"),
September = read.csv("Sales_September_2019.csv"),
October = read.csv("Sales_October_2019.csv"),
November = read.csv("Sales_November_2019.csv"),
December = read.csv("Sales_December_2019.csv")
)
summary(datasets[[1]])#order id and price data type is character so  data is noisy
#Data Exploration
#Data cleaning and removing misding value and null value and combining all data in a unit
library(dplyr)
# Add a 'Month' column to each dataset before combining them
datasets_cleaned <- lapply(names(datasets), function(month) {
data <- datasets[[month]]
data$Month <- month  # Add a 'Month' column with the respective month name
return(data)
})
# Combine all datasets into one data frame
df <- do.call(rbind, datasets_cleaned)
# Check if 'Quantity.Ordered' and 'Price.Each' columns exist
if ("Quantity.Ordered" %in% colnames(df) & "Price.Each" %in% colnames(df)) {
# Ensure 'Quantity.Ordered' and 'Price.Each' are numeric
df$Quantity.Ordered <- as.numeric(df$Quantity.Ordered)
df$Price.Each <- as.numeric(df$Price.Each)
# Create the Total.Sales column
df$Total.Sales <- df$Quantity.Ordered * df$Price.Each
} else {
stop("Columns 'Quantity.Ordered' or 'Price.Each' not found in the dataset")
}
# Remove rows with missing or NA values in any column
df <- df %>%
filter(complete.cases(.))  # Removes rows with NA
# Optionally, drop empty strings as well
df<- df %>%
filter_all(all_vars(. != ""))
# Inspect the cleaned data
head(df)
#Basic summary
# Basic summary of the dataset
summary(df)
# Number of records in the combined dataset
num_records <- nrow(df)
# Range of key values in 'Total.Sales', 'Quantity.Ordered', and 'Price.Each'
range_values <- data.frame(
Total_Sales_Range = range(df$Total.Sales, na.rm = TRUE),
Quantity_Ordered_Range = range(df$Quantity.Ordered, na.rm = TRUE),
Price_Each_Range = range(df$Price.Each, na.rm = TRUE)
)
# Basic statistics: Total sales and average quantity ordered
total_sales <- sum(df$Total.Sales, na.rm = TRUE)
avg_quantity <- mean(df$Quantity.Ordered, na.rm = TRUE)
# Display results
cat("Number of records:", num_records, "\n")
cat("Total Sales:", total_sales, "\n")
cat("Average Quantity Ordered:", avg_quantity, "\n")
print(range_values)
# Calculate sales and average for each month
monthly_summary <- df %>%
group_by(Month) %>%
summarise(
Total_Sales = sum(Total.Sales, na.rm = TRUE),
Average_Quantity = mean(Quantity.Ordered, na.rm = TRUE)
)
# Sorting the monthly summary by Total Sales
monthly_summary_sorted <- monthly_summary %>%
arrange(Total_Sales)
# Display the sorted summary
print(monthly_summary_sorted)
#Date and Time Analysis:
#correcting the date format in a proper manner
df$Order.Date <- as.POSIXct(df$Order.Date, format = "%m/%d/%y %H:%M")
df$Month <- format(df$Order.Date, "%m")
df$Day <- format(df$Order.Date, "%d")
df$Hour <- format(df$Order.Date, "%H")
#Data Preprocessing:
#insuring the appropriate format for analysis of coloumns
summary(df)
# Set working directory
setwd("/Users/sandipmahata/Desktop/data mining/Sales Dataset")
# Importing all datasets into a list
datasets <- list(
January = read.csv("Sales_January_2019.csv"),
February = read.csv("Sales_February_2019.csv"),
March = read.csv("Sales_March_2019.csv"),
April = read.csv("Sales_April_2019.csv"),
May = read.csv("Sales_May_2019.csv"),
June = read.csv("Sales_June_2019.csv"),
July = read.csv("Sales_July_2019.csv"),
August = read.csv("Sales_August_2019.csv"),
September = read.csv("Sales_September_2019.csv"),
October = read.csv("Sales_October_2019.csv"),
November = read.csv("Sales_November_2019.csv"),
December = read.csv("Sales_December_2019.csv")
)
summary(datasets[[1]])#order id and price data type is character so  data is noisy
#Data Exploration
#Data cleaning and removing misding value and null value and combining all data in a unit
library(dplyr)
# Add a 'Month' column to each dataset before combining them
datasets_cleaned <- lapply(names(datasets), function(month) {
data <- datasets[[month]]
data$Month <- month  # Add a 'Month' column with the respective month name
return(data)
})
# Combine all datasets into one data frame
df <- do.call(rbind, datasets_cleaned)
# Check if 'Quantity.Ordered' and 'Price.Each' columns exist
if ("Quantity.Ordered" %in% colnames(df) & "Price.Each" %in% colnames(df)) {
# Ensure 'Quantity.Ordered' and 'Price.Each' are numeric
df$Quantity.Ordered <- as.numeric(df$Quantity.Ordered)
df$Price.Each <- as.numeric(df$Price.Each)
# Create the Total.Sales column
df$Total.Sales <- df$Quantity.Ordered * df$Price.Each
} else {
stop("Columns 'Quantity.Ordered' or 'Price.Each' not found in the dataset")
}
# Remove rows with missing or NA values in any column
df <- df %>%
filter(complete.cases(.))  # Removes rows with NA
# Optionally, drop empty strings as well
df<- df %>%
filter_all(all_vars(. != ""))
# Inspect the cleaned data
head(df)
#Basic summary
# Basic summary of the dataset
summary(df)
# Number of records in the combined dataset
num_records <- nrow(df)
# Range of key values in 'Total.Sales', 'Quantity.Ordered', and 'Price.Each'
range_values <- data.frame(
Total_Sales_Range = range(df$Total.Sales, na.rm = TRUE),
Quantity_Ordered_Range = range(df$Quantity.Ordered, na.rm = TRUE),
Price_Each_Range = range(df$Price.Each, na.rm = TRUE)
)
# Basic statistics: Total sales and average quantity ordered
total_sales <- sum(df$Total.Sales, na.rm = TRUE)
avg_quantity <- mean(df$Quantity.Ordered, na.rm = TRUE)
# Display results
cat("Number of records:", num_records, "\n")
cat("Total Sales:", total_sales, "\n")
cat("Average Quantity Ordered:", avg_quantity, "\n")
print(range_values)
# Calculate sales and average for each month
monthly_summary <- df %>%
group_by(Month) %>%
summarise(
Total_Sales = sum(Total.Sales, na.rm = TRUE),
Average_Quantity = mean(Quantity.Ordered, na.rm = TRUE)
)
# Sorting the monthly summary by Total Sales
monthly_summary_sorted <- monthly_summary %>%
arrange(Total_Sales)
# Display the sorted summary
print(monthly_summary_sorted)
#Date and Time Analysis:
#correcting the date format in a proper manner
df$Order.Date <- as.POSIXct(df$Order.Date, format = "%m/%d/%y %H:%M")
df$Month <- format(df$Order.Date, "%m")
df$Day <- format(df$Order.Date, "%d")
df$Hour <- format(df$Order.Date, "%H")
#Data Preprocessing:
#insuring the appropriate format for analysis of coloumns
summary(df)
#converting day hour and month in numerical variable
df$Month = as.numeric(df$Month)
df$Day = as.numeric(df$Day)
df$Hour = as.numeric(df$Hour)
# Drop the 'Order.Date' column
df <- df %>%
select(-Order.Date)
# Check the result to ensure 'Order.Date' is removed
head(df)
#Feature Engineering
# Feature Engineering: Split 'Purchase.Address' into 'Street', 'City', 'State', and 'Zip.Code'
library(tidyr)
# Ensure Purchase.Address is character type and then extract the components using regular expressions
df <- df %>%
mutate(
Purchase.Address = as.character(Purchase.Address)  # Ensure it's a character type
) %>%
# Use regular expression to extract Street, City, State, and Zip.Code directly
extract(
Purchase.Address,
into = c("Street", "City", "State", "Zip.Code"),
regex = "^(.+),\\s*(.+),\\s*([A-Z]{2})\\s*(\\d{5})$"
) %>%
# Trim whitespace for all fields just in case
mutate(
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Count duplicate Order.ID values
duplicate_count <- df %>%
group_by(Order.ID) %>%
summarise(Order_Count = n()) %>%
filter(Order_Count > 1) %>%
nrow()
# Display the count of duplicate Order.IDs
cat("Number of duplicate Order.IDs:", duplicate_count, "\n")
#assuming order id is as per the same customer and making new dataframe
# Clean and trim whitespace from relevant columns
df <- df %>%
mutate(
Order.ID = trimws(Order.ID),  # Trim whitespace
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Find repeated Order.IDs only
repeated_orders <- df %>%
group_by(Order.ID) %>%
filter(n() > 1)  # Only keep Order.IDs that appear more than once
# Create a new data frame with repeated Order.IDs, their products, and total sales
order_id_df <- repeated_orders %>%
group_by(Order.ID, Street, City, State, Zip.Code) %>%
summarise(
Products = paste(unique(Product), collapse = ", "),  # Concatenate product names into a single string
Repeat_Count = n(),  # Count how many times each repeated Order.ID appears
Total_Sales = sum(Total.Sales, na.rm = TRUE),  # Sum of Total Sales for each repeated Order.ID
.groups = 'drop'  # Avoid warning about grouping
) %>%
# Replace empty strings and NA values with "Not Available"
mutate(
Order.ID = ifelse(Order.ID == "", "Not Available", Order.ID),
Street = ifelse(Street == "", "Not Available", Street),
City = ifelse(is.na(City), "Not Available", City),
State = ifelse(State == "", "Not Available", State),
Zip.Code = ifelse(Zip.Code == "", "Not Available", Zip.Code)
) %>%
# Remove rows where Total_Sales is 0
filter(Total_Sales > 0)
# Display the new data frame
print(order_id_df)
# Install and load required libraries
library(arules)
# Clean and trim whitespace from relevant columns
df <- df %>%
mutate(
Order.ID = trimws(Order.ID),  # Trim whitespace
Product = trimws(Product)  # Trim Product names
)
# Convert data into a transaction format
transactions <- df %>%
group_by(Order.ID) %>%
summarise(Products = list(unique(Product))) %>%  # Group products by Order.ID
pull(Products)  # Extract the product lists as a vector
# Convert the list of transactions into transactions class
transactions <- as(transactions, "transactions")
# Display summary of transactions
summary(transactions)
# Applying Apriori algorithm with lower support
rules <- apriori(transactions, parameter = list(supp = 0.001, conf = 0.4))
# Check if rules are generated
if (length(rules) > 0) {
# Display top rules sorted by lift
inspect(sort(rules, by = "lift")[1:10])
} else {
print("No rules found. Try lowering the support or confidence.")
}
# Create the 'time_frame' column based on the 'Hour' column
df <- df %>%
mutate(
time_frame = case_when(
Hour >= 0 & Hour < 8 ~ "Morning",
Hour >= 8 & Hour < 16 ~ "Evening",
Hour >= 16 & Hour < 24 ~ "Night",
TRUE ~ NA_character_  # In case there are any unexpected values
)
)
# Inspect the updated dataframe
head(df)
View(df)
View(df)
View(df)
# Set working directory
setwd("/Users/sandipmahata/Desktop/data mining/Sales Dataset")
# Importing all datasets into a list
datasets <- list(
January = read.csv("Sales_January_2019.csv"),
February = read.csv("Sales_February_2019.csv"),
March = read.csv("Sales_March_2019.csv"),
April = read.csv("Sales_April_2019.csv"),
May = read.csv("Sales_May_2019.csv"),
June = read.csv("Sales_June_2019.csv"),
July = read.csv("Sales_July_2019.csv"),
August = read.csv("Sales_August_2019.csv"),
September = read.csv("Sales_September_2019.csv"),
October = read.csv("Sales_October_2019.csv"),
November = read.csv("Sales_November_2019.csv"),
December = read.csv("Sales_December_2019.csv")
)
summary(datasets[[1]])#order id and price data type is character so  data is noisy
#Data Exploration
#Data cleaning and removing misding value and null value and combining all data in a unit
library(dplyr)
# Add a 'Month' column to each dataset before combining them
datasets_cleaned <- lapply(names(datasets), function(month) {
data <- datasets[[month]]
data$Month <- month  # Add a 'Month' column with the respective month name
return(data)
})
# Combine all datasets into one data frame
df <- do.call(rbind, datasets_cleaned)
# Check if 'Quantity.Ordered' and 'Price.Each' columns exist
if ("Quantity.Ordered" %in% colnames(df) & "Price.Each" %in% colnames(df)) {
# Ensure 'Quantity.Ordered' and 'Price.Each' are numeric
df$Quantity.Ordered <- as.numeric(df$Quantity.Ordered)
df$Price.Each <- as.numeric(df$Price.Each)
# Create the Total.Sales column
df$Total.Sales <- df$Quantity.Ordered * df$Price.Each
} else {
stop("Columns 'Quantity.Ordered' or 'Price.Each' not found in the dataset")
}
# Remove rows with missing or NA values in any column
df <- df %>%
filter(complete.cases(.))  # Removes rows with NA
# Optionally, drop empty strings as well
df<- df %>%
filter_all(all_vars(. != ""))
# Inspect the cleaned data
head(df)
#Basic summary
# Basic summary of the dataset
summary(df)
# Number of records in the combined dataset
num_records <- nrow(df)
# Range of key values in 'Total.Sales', 'Quantity.Ordered', and 'Price.Each'
range_values <- data.frame(
Total_Sales_Range = range(df$Total.Sales, na.rm = TRUE),
Quantity_Ordered_Range = range(df$Quantity.Ordered, na.rm = TRUE),
Price_Each_Range = range(df$Price.Each, na.rm = TRUE)
)
# Basic statistics: Total sales and average quantity ordered
total_sales <- sum(df$Total.Sales, na.rm = TRUE)
avg_quantity <- mean(df$Quantity.Ordered, na.rm = TRUE)
# Display results
cat("Number of records:", num_records, "\n")
cat("Total Sales:", total_sales, "\n")
cat("Average Quantity Ordered:", avg_quantity, "\n")
print(range_values)
# Calculate sales and average for each month
monthly_summary <- df %>%
group_by(Month) %>%
summarise(
Total_Sales = sum(Total.Sales, na.rm = TRUE),
Average_Quantity = mean(Quantity.Ordered, na.rm = TRUE)
)
# Sorting the monthly summary by Total Sales
monthly_summary_sorted <- monthly_summary %>%
arrange(Total_Sales)
# Display the sorted summary
print(monthly_summary_sorted)
#Date and Time Analysis:
#correcting the date format in a proper manner
df$Order.Date <- as.POSIXct(df$Order.Date, format = "%m/%d/%y %H:%M")
df$Month <- format(df$Order.Date, "%m")
df$Day <- format(df$Order.Date, "%d")
df$Hour <- format(df$Order.Date, "%H")
#Data Preprocessing:
#insuring the appropriate format for analysis of coloumns
summary(df)
#converting day hour and month in numerical variable
df$Month = as.numeric(df$Month)
df$Day = as.numeric(df$Day)
df$Hour = as.numeric(df$Hour)
# Drop the 'Order.Date' column
df <- df %>%
select(-Order.Date)
# Check the result to ensure 'Order.Date' is removed
head(df)
#Feature Engineering
# Feature Engineering: Split 'Purchase.Address' into 'Street', 'City', 'State', and 'Zip.Code'
library(tidyr)
# Ensure Purchase.Address is character type and then extract the components using regular expressions
df <- df %>%
mutate(
Purchase.Address = as.character(Purchase.Address)  # Ensure it's a character type
) %>%
# Use regular expression to extract Street, City, State, and Zip.Code directly
extract(
Purchase.Address,
into = c("Street", "City", "State", "Zip.Code"),
regex = "^(.+),\\s*(.+),\\s*([A-Z]{2})\\s*(\\d{5})$"
) %>%
# Trim whitespace for all fields just in case
mutate(
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Count duplicate Order.ID values
duplicate_count <- df %>%
group_by(Order.ID) %>%
summarise(Order_Count = n()) %>%
filter(Order_Count > 1) %>%
nrow()
# Display the count of duplicate Order.IDs
cat("Number of duplicate Order.IDs:", duplicate_count, "\n")
#assuming order id is as per the same customer and making new dataframe
# Clean and trim whitespace from relevant columns
df <- df %>%
mutate(
Order.ID = trimws(Order.ID),  # Trim whitespace
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Find repeated Order.IDs only
repeated_orders <- df %>%
group_by(Order.ID) %>%
filter(n() > 1)  # Only keep Order.IDs that appear more than once
# Create a new data frame with repeated Order.IDs, their products, and total sales
order_id_df <- repeated_orders %>%
group_by(Order.ID, Street, City, State, Zip.Code) %>%
summarise(
Products = paste(unique(Product), collapse = ", "),  # Concatenate product names into a single string
Repeat_Count = n(),  # Count how many times each repeated Order.ID appears
Total_Sales = sum(Total.Sales, na.rm = TRUE),  # Sum of Total Sales for each repeated Order.ID
.groups = 'drop'  # Avoid warning about grouping
) %>%
# Replace empty strings and NA values with "Not Available"
mutate(
Order.ID = ifelse(Order.ID == "", "Not Available", Order.ID),
Street = ifelse(Street == "", "Not Available", Street),
City = ifelse(is.na(City), "Not Available", City),
State = ifelse(State == "", "Not Available", State),
Zip.Code = ifelse(Zip.Code == "", "Not Available", Zip.Code)
) %>%
# Remove rows where Total_Sales is 0
filter(Total_Sales > 0)
# Display the new data frame
print(order_id_df)
View(order_id_df)
View(order_id_df)
View(transactions)
View(sales_summary)
View(sales_by_time_state)
View(state_sales_summary)
View(time_frame_summary)
View(geocoded_cities)
