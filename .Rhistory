Zip.Code = trimws(Zip.Code)
)
# Create a new 'Week' column based on the 'Day' column
df <- df %>%
mutate(
Week = case_when(
Day >= 0 & Day <= 7 ~ 1,
Day >= 8 & Day <= 14 ~ 2,
Day >= 15 & Day <= 21 ~ 3,
Day >= 22 & Day <= 28 ~ 4,
Day >= 29 & Day <= 35 ~ 5,
TRUE ~ NA_real_  # In case there's an invalid day value
)
)
# Inspect the new 'Week' column
head(df[, c("Day", "Week")], 10)
# Count duplicate Order.ID values
duplicate_count <- df %>%
group_by(Order.ID) %>%
summarise(Order_Count = n()) %>%
filter(Order_Count > 1) %>%
nrow()
# Display the count of duplicate Order.IDs
cat("Number of duplicate Order.IDs:", duplicate_count, "\n")
#assuming order id is as per the same customer and making new dataframe
# Clean and trim whitespace from relevant columns
df <- df %>%
mutate(
Order.ID = trimws(Order.ID),  # Trim whitespace
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Create a new data frame with unique Order.IDs, their repetition count, and total sales
order_id_df <- df %>%
group_by(Order.ID, Street, City, State, Zip.Code) %>%
summarise(
Repeat_Count = n(),  # Count how many times each Order.ID appears
Total_Sales = sum(Total.Sales, na.rm = TRUE),  # Sum of Total Sales for each Order.ID
.groups = 'drop'  # Avoid warning about grouping
) %>%
# Replace empty strings and NA values with "Not Available"
mutate(
Order.ID = ifelse(Order.ID == "", "Not Available", Order.ID),
Street = ifelse(Street == "", "Not Available", Street),
City = ifelse(is.na(City), "Not Available", City),
State = ifelse(State == "", "Not Available", State),
Zip.Code = ifelse(Zip.Code == "", "Not Available", Zip.Code)
) %>%
# Remove rows where Total_Sales is 0
filter(Total_Sales > 0)
# Display the new data frame
print(order_id_df)
# Create the 'time_frame' column based on the 'Hour' column
df <- df %>%
mutate(
time_frame = case_when(
Hour >= 0 & Hour < 8 ~ "Morning",
Hour >= 8 & Hour < 16 ~ "Evening",
Hour >= 16 & Hour < 24 ~ "Night",
TRUE ~ NA_character_  # In case there are any unexpected values
)
)
# Inspect the updated dataframe
head(df)
#Data visualization
library(ggplot2)
# Summarize total sales by state
state_sales_summary <- df %>%
group_by(State) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
# Create a bar plot to visualize total sales for each state
ggplot(state_sales_summary, aes(x = State, y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(
title = "Total Sales by State",
x = "State",
y = "Total Sales"
) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Count the total Order IDs by State
order_count_by_state <- df %>%
group_by(State) %>%
summarise(Total_Orders = n_distinct(Order.ID)) %>%  # Count unique Order IDs
arrange(desc(Total_Orders))  # Sort by Total Orders in descending order
# Display the summarized data (optional)
print(order_count_by_state)
# Create a bar plot for total Order IDs by State
ggplot(order_count_by_state, aes(x = reorder(State, -Total_Orders), y = Total_Orders)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Total Order Counts by State",
x = "State",
y = "Total Order Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better visibility
# Summarize Total Sales by Week
weekly_sales <- df %>%
group_by(Week) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
# Create a line graph for Total.Sales by Week
ggplot(weekly_sales, aes(x = Week, y = Total_Sales)) +
geom_line(color = "blue", size = 1) +  # Line graph
geom_point(color = "red", size = 2) +  # Points for each week
labs(title = "Total Sales by Week",
x = "Week",
y = "Total Sales") +
theme_minimal()
# Summarize the total sales by time_frame and Month
sales_summary <- df %>%
group_by(Month, time_frame) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE), .groups = 'drop')
# Create the grouped bar plot
ggplot(sales_summary, aes(x = Month, y = Total_Sales, fill = time_frame)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Total Sales by Time Frame and Month",
x = "Month",
y = "Total Sales") +
scale_fill_manual(values = c("Morning" = "lightblue", "Evening" = "orange", "Night" = "darkblue")) +
theme_minimal()
library(ggmap)
library(ggmap)
install.packages("ggmap")
library(ggmap)
library(dplyr)
library(ggplot2)
# Replace this with your actual Google Maps API Key
register_google(key = "AIzaSyCLd63wsizYTe_sSQ1jEkqo-evZ9AqBMWw")
# Assuming you already have your sales dataset in 'df'
# Let's first check and clean up the 'City' column in case there are issues
df <- df %>%
mutate(City = trimws(City))  # Trim any extra spaces from city names
# Get unique city names from the dataset
unique_cities <- unique(df$City)
# Geocode the cities to get latitude and longitude (this will take some time depending on the number of cities)
city_coords <- geocode(unique_cities)
install.packages("tidygeocoder")
# Load necessary libraries
library(tidygeocoder)
library(dplyr)
# Clean city names in case there are issues
df <- df %>%
mutate(City = trimws(City))
# Get unique city names
unique_cities <- unique(df$City)
# Geocode the cities using Nominatim (OpenStreetMap)
city_coords <- unique_cities %>%
as.data.frame() %>%
rename(city = ".") %>%
geocode(city, method = 'osm', full_results = FALSE)
# View the city coordinates
print(city_coords)
install.packages("leaflet")
# Load the libraries
library(leaflet)
library(tidygeocoder)
library(dplyr)
# Example dataset with city names
df <- data.frame(City = c("New York", "Los Angeles", "Chicago", "Houston", "Phoenix"))
# Geocode the cities using Nominatim (OpenStreetMap)
df_geocoded <- df %>%
geocode(City, method = 'osm', full_results = FALSE)
# Print the geocoded cities with their latitude and longitude
print(df_geocoded)
# Create a leaflet map and add city dots
leaflet(df_geocoded) %>%
addTiles() %>%  # Add default OpenStreetMap tiles
addCircles(lng = ~long, lat = ~lat, popup = ~City, radius = 50000, weight = 1, color = "#0073e6")
leaflet(df_geocoded) %>%
addTiles() %>%
addCircles(lng = ~long, lat = ~lat, popup = ~City, radius = 50000, weight = 1, color = "#FF5733", fillOpacity = 0.7) %>%
addMarkers(lng = ~long, lat = ~lat, label = ~City)
View(df)
# Set working directory
setwd("/Users/sandipmahata/Desktop/data mining/Sales Dataset")
# Importing all datasets into a list
datasets <- list(
January = read.csv("Sales_January_2019.csv"),
February = read.csv("Sales_February_2019.csv"),
March = read.csv("Sales_March_2019.csv"),
April = read.csv("Sales_April_2019.csv"),
May = read.csv("Sales_May_2019.csv"),
June = read.csv("Sales_June_2019.csv"),
July = read.csv("Sales_July_2019.csv"),
August = read.csv("Sales_August_2019.csv"),
September = read.csv("Sales_September_2019.csv"),
October = read.csv("Sales_October_2019.csv"),
November = read.csv("Sales_November_2019.csv"),
December = read.csv("Sales_December_2019.csv")
)
summary(datasets[[1]])#order id and price data type is character so  data is noisy
#Data Exploration
#Data cleaning and removing misding value and null value and combining all data in a unit
library(dplyr)
# Add a 'Month' column to each dataset before combining them
datasets_cleaned <- lapply(names(datasets), function(month) {
data <- datasets[[month]]
data$Month <- month  # Add a 'Month' column with the respective month name
return(data)
})
# Combine all datasets into one data frame
df <- do.call(rbind, datasets_cleaned)
# Check if 'Quantity.Ordered' and 'Price.Each' columns exist
if ("Quantity.Ordered" %in% colnames(df) & "Price.Each" %in% colnames(df)) {
# Ensure 'Quantity.Ordered' and 'Price.Each' are numeric
df$Quantity.Ordered <- as.numeric(df$Quantity.Ordered)
df$Price.Each <- as.numeric(df$Price.Each)
# Create the Total.Sales column
df$Total.Sales <- df$Quantity.Ordered * df$Price.Each
} else {
stop("Columns 'Quantity.Ordered' or 'Price.Each' not found in the dataset")
}
# Inspect the cleaned data
head(df)
#Basic summary
# Basic summary of the dataset
summary(df)
# Number of records in the combined dataset
num_records <- nrow(df)
# Range of key values in 'Total.Sales', 'Quantity.Ordered', and 'Price.Each'
range_values <- data.frame(
Total_Sales_Range = range(df$Total.Sales, na.rm = TRUE),
Quantity_Ordered_Range = range(df$Quantity.Ordered, na.rm = TRUE),
Price_Each_Range = range(df$Price.Each, na.rm = TRUE)
)
# Basic statistics: Total sales and average quantity ordered
total_sales <- sum(df$Total.Sales, na.rm = TRUE)
avg_quantity <- mean(df$Quantity.Ordered, na.rm = TRUE)
# Display results
cat("Number of records:", num_records, "\n")
cat("Total Sales:", total_sales, "\n")
cat("Average Quantity Ordered:", avg_quantity, "\n")
print(range_values)
# Calculate sales and average for each month
monthly_summary <- df %>%
group_by(Month) %>%
summarise(
Total_Sales = sum(Total.Sales, na.rm = TRUE),
Average_Quantity = mean(Quantity.Ordered, na.rm = TRUE)
)
# Sorting the monthly summary by Total Sales
monthly_summary_sorted <- monthly_summary %>%
arrange(Total_Sales)
# Display the sorted summary
print(monthly_summary_sorted)
#Date and Time Analysis:
#correcting the date format in a proper manner
df$Order.Date <- as.POSIXct(df$Order.Date, format = "%m/%d/%y %H:%M")
df$Month <- format(df$Order.Date, "%m")
df$Day <- format(df$Order.Date, "%d")
df$Hour <- format(df$Order.Date, "%H")
#Data Preprocessing:
#insuring the appropriate format for analysis of coloumns
summary(df)
#converting day hour and month in numerical variable
df$Month = as.numeric(df$Month)
df$Day = as.numeric(df$Day)
df$Hour = as.numeric(df$Hour)
# Drop the 'Order.Date' column
df <- df %>%
select(-Order.Date)
# Check the result to ensure 'Order.Date' is removed
head(df)
#Feature Engineering
# Feature Engineering: Split 'Purchase.Address' into 'Street', 'City', 'State', and 'Zip.Code'
library(tidyr)
# Ensure Purchase.Address is character type and then extract the components using regular expressions
df <- df %>%
mutate(
Purchase.Address = as.character(Purchase.Address)  # Ensure it's a character type
) %>%
# Use regular expression to extract Street, City, State, and Zip.Code directly
extract(
Purchase.Address,
into = c("Street", "City", "State", "Zip.Code"),
regex = "^(.+),\\s*(.+),\\s*([A-Z]{2})\\s*(\\d{5})$"
) %>%
# Trim whitespace for all fields just in case
mutate(
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Create a new 'Week' column based on the 'Day' column
df <- df %>%
mutate(
Week = case_when(
Day >= 0 & Day <= 7 ~ 1,
Day >= 8 & Day <= 14 ~ 2,
Day >= 15 & Day <= 21 ~ 3,
Day >= 22 & Day <= 28 ~ 4,
Day >= 29 & Day <= 35 ~ 5,
TRUE ~ NA_real_  # In case there's an invalid day value
)
)
# Inspect the new 'Week' column
head(df[, c("Day", "Week")], 10)
# Count duplicate Order.ID values
duplicate_count <- df %>%
group_by(Order.ID) %>%
summarise(Order_Count = n()) %>%
filter(Order_Count > 1) %>%
nrow()
# Display the count of duplicate Order.IDs
cat("Number of duplicate Order.IDs:", duplicate_count, "\n")
#assuming order id is as per the same customer and making new dataframe
# Clean and trim whitespace from relevant columns
df <- df %>%
mutate(
Order.ID = trimws(Order.ID),  # Trim whitespace
Street = trimws(Street),
City = trimws(City),
State = trimws(State),
Zip.Code = trimws(Zip.Code)
)
# Create a new data frame with unique Order.IDs, their repetition count, and total sales
order_id_df <- df %>%
group_by(Order.ID, Street, City, State, Zip.Code) %>%
summarise(
Repeat_Count = n(),  # Count how many times each Order.ID appears
Total_Sales = sum(Total.Sales, na.rm = TRUE),  # Sum of Total Sales for each Order.ID
.groups = 'drop'  # Avoid warning about grouping
) %>%
# Replace empty strings and NA values with "Not Available"
mutate(
Order.ID = ifelse(Order.ID == "", "Not Available", Order.ID),
Street = ifelse(Street == "", "Not Available", Street),
City = ifelse(is.na(City), "Not Available", City),
State = ifelse(State == "", "Not Available", State),
Zip.Code = ifelse(Zip.Code == "", "Not Available", Zip.Code)
) %>%
# Remove rows where Total_Sales is 0
filter(Total_Sales > 0)
# Display the new data frame
print(order_id_df)
# Create the 'time_frame' column based on the 'Hour' column
df <- df %>%
mutate(
time_frame = case_when(
Hour >= 0 & Hour < 8 ~ "Morning",
Hour >= 8 & Hour < 16 ~ "Evening",
Hour >= 16 & Hour < 24 ~ "Night",
TRUE ~ NA_character_  # In case there are any unexpected values
)
)
# Inspect the updated dataframe
head(df)
#Data visualization
library(ggplot2)
# Summarize total sales by state
state_sales_summary <- df %>%
group_by(State) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
# Create a bar plot to visualize total sales for each state
ggplot(state_sales_summary, aes(x = State, y = Total_Sales)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(
title = "Total Sales by State",
x = "State",
y = "Total Sales"
) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Count the total Order IDs by State
order_count_by_state <- df %>%
group_by(State) %>%
summarise(Total_Orders = n_distinct(Order.ID)) %>%  # Count unique Order IDs
arrange(desc(Total_Orders))  # Sort by Total Orders in descending order
# Display the summarized data (optional)
print(order_count_by_state)
# Create a bar plot for total Order IDs by State
ggplot(order_count_by_state, aes(x = reorder(State, -Total_Orders), y = Total_Orders)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Total Order Counts by State",
x = "State",
y = "Total Order Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better visibility
# Summarize Total Sales by Week
weekly_sales <- df %>%
group_by(Week) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE))
# Create a line graph for Total.Sales by Week
ggplot(weekly_sales, aes(x = Week, y = Total_Sales)) +
geom_line(color = "blue", size = 1) +  # Line graph
geom_point(color = "red", size = 2) +  # Points for each week
labs(title = "Total Sales by Week",
x = "Week",
y = "Total Sales") +
theme_minimal()
# Summarize the total sales by time_frame and Month
sales_summary <- df %>%
group_by(Month, time_frame) %>%
summarise(Total_Sales = sum(Total.Sales, na.rm = TRUE), .groups = 'drop')
# Create the grouped bar plot
ggplot(sales_summary, aes(x = Month, y = Total_Sales, fill = time_frame)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Total Sales by Time Frame and Month",
x = "Month",
y = "Total Sales") +
scale_fill_manual(values = c("Morning" = "lightblue", "Evening" = "orange", "Night" = "darkblue")) +
theme_minimal()
View(df)
View(df)
# Load the libraries
library(leaflet)
library(tidygeocoder)
library(dplyr)
# Example dataframe 'df' containing customer city names
# Replace this with your actual dataframe
map <- df$City
# Count the number of customers in each city
city_counts <- map %>%
group_by(City) %>%
summarise(Frequency = n())  # This will give you the number of customers per city
# Load the libraries
library(leaflet)
library(tidygeocoder)
library(dplyr)
# Assuming 'df' is your actual dataframe containing a column named 'City'
# Count the number of customers in each city
city_counts <- df %>%
group_by(City) %>%
summarise(Frequency = n(), .groups = 'drop')  # This will give you the number of customers per city
# Geocode the cities (using OpenStreetMap)
geocoded_cities <- city_counts %>%
geocode(City, method = 'osm', full_results = FALSE)  # Geocode cities to get latitude and longitude
# Ensure 'geocoded_cities' has the required columns for plotting
# It should have 'long' and 'lat' from geocoding
if (!all(c("long", "lat") %in% colnames(geocoded_cities))) {
stop("Geocoding failed: Missing 'long' or 'lat' columns.")
}
# Function to map frequency to darker colors
get_color <- function(frequency) {
if (frequency == 1) {
return("#ADD8E6")  # Light Blue
} else if (frequency == 2) {
return("#0073e6")  # Medium Blue
} else {
return("#000080")  # Dark Blue
}
}
# Plot the cities on a leaflet map
leaflet(geocoded_cities) %>%
addTiles() %>%  # Add base map tiles
addCircles(
lng = ~long, lat = ~lat, popup = ~City,
radius = 50000, weight = 1, fillOpacity = 0.7,
color = ~sapply(Frequency, get_color)  # Adjust circle color based on frequency
)
# Load the libraries
library(leaflet)
library(tidygeocoder)
library(dplyr)
# Assuming 'df' is your actual dataframe containing columns 'City' and 'State'
# Count the number of customers in each city by state
city_counts <- df %>%
group_by(State, City) %>%
summarise(Frequency = n(), .groups = 'drop')  # This will give you the number of customers per city by state
# Geocode the cities (using OpenStreetMap)
geocoded_cities <- city_counts %>%
geocode(paste(City, State, sep = ", "), method = 'osm', full_results = FALSE)  # Geocode cities to get latitude and longitude
# Load the libraries
library(leaflet)
library(tidygeocoder)
library(dplyr)
# Assuming 'df' is your actual dataframe containing columns 'City' and 'State'
# Example dataframe (replace this with your actual dataframe)
# df <- data.frame(City = c("Boston", "Portland", "San Francisco", "Los Angeles"),
#                  State = c("MA", "OR", "CA", "CA"))
# Count the number of customers in each city by state
city_counts <- df %>%
group_by(State, City) %>%
summarise(Frequency = n(), .groups = 'drop')  # This will give you the number of customers per city by state
# Create a new column combining City and State for geocoding
city_counts <- city_counts %>%
mutate(Location = paste(City, State, sep = ", "))  # Create a Location column
# Geocode the cities (using OpenStreetMap)
geocoded_cities <- city_counts %>%
geocode(Location, method = 'osm', full_results = FALSE)  # Geocode cities to get latitude and longitude
# Ensure 'geocoded_cities' has the required columns for plotting
# It should have 'long' and 'lat' from geocoding
if (!all(c("long", "lat") %in% colnames(geocoded_cities))) {
stop("Geocoding failed: Missing 'long' or 'lat' columns.")
}
# Combine geocoded data with frequency data
geocoded_cities <- geocoded_cities %>%
left_join(city_counts, by = c("Location" = "Location"))  # Join to bring in Frequency
# Function to map frequency to darker colors
get_color <- function(frequency) {
if (frequency == 1) {
return("#ADD8E6")  # Light Blue
} else if (frequency == 2) {
return("#0073e6")  # Medium Blue
} else {
return("#000080")  # Dark Blue
}
}
# Determine the size of circles based on frequency
# Here, you can adjust the multiplier to control the circle sizes
size_multiplier <- 1000  # Adjust this value to change size scaling
# Plot the cities on a leaflet map
leaflet(geocoded_cities) %>%
addTiles() %>%  # Add base map tiles
addCircles(
lng = ~long, lat = ~lat, popup = ~paste(City, State, "<br>Frequency:", Frequency),
radius = ~Frequency * size_multiplier,  # Circle size based on frequency
weight = 1, fillOpacity = 0.7,
color = ~sapply(Frequency, get_color)  # Adjust circle color based on frequency
)
